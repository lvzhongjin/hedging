{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from time import sleep\n",
    "from itertools import compress\n",
    "\n",
    "volkws=['btu','bls','bcf','mcf','cfe']\n",
    "prodkws=['bbls)', 'bcf)','bcfs)',\"cfe)\",\"mcf)\",\"mcfs)\"]\n",
    "drvkws=['swap','swaps','put','puts','collar','collars','Henry Hub']\n",
    "price=['average','price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### the code is still under development; descriptions of each step need to be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def table_scrapper_v2(article):\n",
    "    tables=article.find_all('table')\n",
    "    tb_count=1 #bug prevention\n",
    "    df_list=[]\n",
    "    des_list=[]\n",
    "    index_list=[]\n",
    "    for ii in range(len(tables)):\n",
    "        temp1=\"\"\n",
    "        temp=\"\".join(map(str.lower, tables[ii].get_text())) #((\"fixed-price\" in temp) or ((\"fixed price\" in temp)))\\\n",
    "        cond1= any(volkw in temp for volkw in volkws) and any(drvkw in temp for drvkw in drvkws)\n",
    "        cond2=False\n",
    "        if cond1==False: #go to the previous paragraph\n",
    "            for kth in range(6):\n",
    "                if len(tables[ii].find_all_previous()[kth].get_text())>15: break\n",
    "            temp1=\"\".join(map(str.lower, [s.get_text(strip=True) for s \\\n",
    "                in tables[ii].find_all_previous()[:kth+1]]))\n",
    "            cond1= any(drvkw in re.split(r'\\W+',temp) for drvkw in drvkws) and any(volkw in temp1 for volkw in volkws)\n",
    "            cond2= any(drvkw in re.split(r'\\W+',temp1) for drvkw in drvkws) and any(volkw in temp for volkw in volkws)\n",
    "        cond3= all(x not in temp for x in ['balance sheet','income','liabiliti','earnings']) and (all(pricekw in temp for pricekw in price) or all(pricekw in temp1 for pricekw in price))\n",
    "        if (cond1 or cond2):\n",
    "            rows=tables[ii].find_all(\"tr\")\n",
    "            l=len(rows)\n",
    "            if l>2: #skip tables that are actuallly paragraph\n",
    "                lst=[]\n",
    "                lst_colspan=[None]*l\n",
    "                i=0\n",
    "                for row in rows:\n",
    "                    lst_temp=[cell.get_text(strip=True) for cell in row.find_all(\"td\")+row.find_all(\"th\")]\n",
    "                    #             print(len(lst_temp),lst_temp)\n",
    "                    if lst_temp is None: \n",
    "                        continue #bug prevention: empty rows\n",
    "                    #                 elif len(lst_temp)>25: continue #bug prevention?\n",
    "                    else:\n",
    "                        lst_colspan[i]=[cell.get('colspan') for cell in row.find_all(\"td\")+row.find_all(\"th\")]\n",
    "                        if lst_colspan[i].count(None)!=len(lst_colspan[i]): \n",
    "                            act=0\n",
    "                            for j,x in enumerate(lst_colspan[i]):\n",
    "                                if x!=None:\n",
    "                                    for _ in range(int(x)-1):\n",
    "                                        lst_temp.insert(j+act,'')\n",
    "                                        act+=1\n",
    "                        lst.append(lst_temp)\n",
    "                    #                 print(lst_temp)\n",
    "                for k in range(len(lst)):\n",
    "                    for j in range(len(lst[k])):\n",
    "#                         if re.search('\\$(?=.*[0-9])',lst[k][j]): \n",
    "#                             lst[k][j]=re.sub(r'[^\\d.-–\\$]',\"\",lst[k][j]) #$ followed by a number\n",
    "                        lst[k][j]=re.sub('–', '-',lst[k][j])\n",
    "                        lst[k][j]=re.sub('[^\\w\\-\\$\\(\\)% ]', '',lst[k][j])\n",
    "                        if re.search('[\\w%\\$]', lst[k][j])==None:\n",
    "                            lst[k][j]=''\n",
    "                df = pd.DataFrame(lst)\n",
    "                df = df.loc[:,df.apply(lambda x: x.str.contains('\\w')).any(axis=0)] #delete columns that have no '\\w'\n",
    "                mask = df.iloc[:,-1].str.contains('[\\w%\\$]') #shift if the last colum is empty\n",
    "                if sum(filter(None,mask))<df.shape[0]/2:\n",
    "                    df.loc[mask,df.columns!=df.columns[-1]]=df.loc[mask,].iloc[:,1:].values\n",
    "                    df=df.iloc[:,:-1]\n",
    "                df = df.loc[:,df.apply(lambda x: x.str.contains('\\w')).any(axis=0)] #delete columns that have no '\\w'\n",
    "                df.columns = df.iloc[0]\n",
    "                df=df.drop(df.index[0])\n",
    "                df_list.append(df)\n",
    "                des_list.append(temp1)\n",
    "                index_list.append(cond3)\n",
    "    return (des_list,df_list,index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wipe(x):\n",
    "    if re.search('[\\w%\\$]', x)==None: \n",
    "        return \"\"\n",
    "    else:\n",
    "        return x\n",
    "def table_scrapper_volume(article):\n",
    "    tables=article.find_all('table')\n",
    "    tb_count=1 #bug prevention\n",
    "    df_list=[]\n",
    "    des_lst=[]\n",
    "    index_list=[]\n",
    "    \n",
    "    for ii in range(len(tables)):\n",
    "        temp1=\"\"\n",
    "        temp=\"\".join(map(str.lower, tables[ii].get_text())) #((\"fixed-price\" in temp) or ((\"fixed price\" in temp)))\\\n",
    "        cond1= (any(volkw in temp for volkw in prodkws) and any(volkw in temp for volkw in ['production','commmitment'])) \n",
    "        cond2=False\n",
    "        if cond1==False: #go to the previous paragraph\n",
    "            for kth in range(6):\n",
    "                if len(tables[ii].find_all_previous()[kth].get_text())>15: break\n",
    "            temp1=\"\".join(map(str.lower, [s.get_text(strip=True) for s \\\n",
    "                in tables[ii].find_all_previous()[:kth+1]]))\n",
    "#             print('des type',type(temp1),type(temp))\n",
    "            cond1= any(volkw in temp for volkw in prodkws) and 'production' in temp1\n",
    "            cond2= any(volkw in temp1 for volkw in prodkws) and 'production' in temp\n",
    "        cond3= any(volkw in temp for volkw in  ['swap','collar','reserve','realized price','income'])  # delete redundant table\n",
    "        if (cond1 or cond2):\n",
    "            rows=tables[ii].find_all(\"tr\")\n",
    "#             print(ii)\n",
    "            l=len(rows)\n",
    "            if l>2: #skip tables that are actuallly paragraph\n",
    "                lst=[]\n",
    "                lst_colspan=[None]*l\n",
    "                i=0\n",
    "                for row in rows:\n",
    "                    lst_temp=[cell.get_text(strip=True) for cell in row.find_all(\"td\")+row.find_all(\"th\")]\n",
    "                    #             print(len(lst_temp),lst_temp)\n",
    "                    if lst_temp is None: \n",
    "                        continue #bug prevention: empty rows\n",
    "                    #                 elif len(lst_temp)>25: continue #bug prevention?\n",
    "                    else:\n",
    "                        lst_colspan[i]=[cell.get('colspan') for cell in row.find_all(\"td\")+row.find_all(\"th\")]\n",
    "                        if lst_colspan[i].count(None)!=len(lst_colspan[i]): \n",
    "                            act=0\n",
    "                            for j,x in enumerate(lst_colspan[i]):\n",
    "                                if x!=None:\n",
    "                                    for _ in range(int(x)-1):\n",
    "                                        lst_temp.insert(j+act,'')\n",
    "                                        act+=1\n",
    "                        lst.append(lst_temp)\n",
    "                    #                 print(lst_temp)\n",
    "                for k in range(len(lst)):\n",
    "                    for j in range(len(lst[k])):\n",
    "#                         if re.search('\\$(?=.*[0-9])',lst[k][j]): \n",
    "#                             lst[k][j]=re.sub(r'[^\\d.-–\\$]',\"\",lst[k][j]) #$ followed by a number\n",
    "                        lst[k][j]=re.sub('–', '-',lst[k][j])\n",
    "                        lst[k][j]=re.sub('[^\\w\\-\\$\\(\\)% ]', '',lst[k][j])\n",
    "                        if re.search('[\\w%\\$]', lst[k][j])==None:\n",
    "                            lst[k][j]=''\n",
    "                df = pd.DataFrame(lst)\n",
    "#                 df = df.applymap(lambda x: re.sub('–', '-',x))\n",
    "#                 df = df.applymap(wipe) #wipe no-char to \"\"\n",
    "                df = df.loc[:,df.apply(lambda x: x.str.contains('\\w')).any(axis=0)] #delete columns that have no '\\w'\n",
    "                mask = df.iloc[:,-1].str.contains('[\\w%\\$]') #shift if the last colum is empty\n",
    "                if sum(filter(None,mask))<df.shape[0]/2:\n",
    "                    df.loc[mask,df.columns!=df.columns[-1]]=df.loc[mask,].iloc[:,1:].values\n",
    "                    df=df.iloc[:,:-1]\n",
    "                df = df.loc[:,df.apply(lambda x: x.str.contains('\\w')).any(axis=0)] #delete columns that have no '\\w'\n",
    "                df.columns = df.iloc[0]\n",
    "                df=df.drop(df.index[0])\n",
    "                df_list.append(df)\n",
    "                des_lst.append(temp1)\n",
    "                cond3=not cond3\n",
    "                index_list.append(cond3)\n",
    "    return (des_lst,df_list,index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_neg_new(string):\n",
    "    if not string is np.nan:\n",
    "        if re.search('^\\(\\d+', str(string)):\n",
    "            string = re.sub('[\\(\\),]',\"\",str(string))\n",
    "            string = 'Neg'+string\n",
    "            return string\n",
    "        elif re.search('^\\d+', str(string)):\n",
    "            string = re.sub(',',\"\",str(string))\n",
    "            return string\n",
    "        else:\n",
    "            return string\n",
    "    else:\n",
    "        return string\n",
    "\n",
    "def output_table(article,tikcer,fdate,form, path,url):\n",
    "    if path=='hedge/':\n",
    "        des_lst,df_lst,index_lst=table_scrapper_v2(article)\n",
    "    elif path=='volume/':\n",
    "        des_lst,df_lst,index_lst=table_scrapper_volume(article)\n",
    "    if len(index_lst)>1:\n",
    "        if len(list(compress(df_lst, index_lst)))>0:\n",
    "            des_lst=list(compress(des_lst, index_lst))\n",
    "            df_lst=list(compress(df_lst, index_lst))\n",
    "    if len(index_lst)>=1:\n",
    "        with open('./'+path+form+'/'+ticker+str(int(fdate))+'.csv','w') as f:\n",
    "            pass\n",
    "    for i in range(len(df_lst)):\n",
    "        des=des_lst[i]\n",
    "        df = df_lst[i].apply(lambda x: x.str.strip())\n",
    "        df1=df.applymap(convert_neg_new)\n",
    "        with open('log_second'+'.txt','a') as f:\n",
    "            f.writelines('good'+ '\\n')\n",
    "        with open('./'+path+form+'/'+ticker+str(int(fdate))+'.csv','a') as f:\n",
    "            try: df1.to_csv(f,encoding='cp1252')\n",
    "            except: df1.to_csv(f,encoding='utf-8')\n",
    "    if len(df_lst)>1:\n",
    "        index=[df.shape[0]*df.shape[1] for df in df_lst]\n",
    "        zipped_pairs = zip(index, df_lst)\n",
    "        df=sorted(zipped_pairs,reverse=True)[0][1] #choose the biggest table\n",
    "        zipped_pairs = zip(index, des_lst)\n",
    "        des=sorted(zipped_pairs,reverse=True)[0][1]\n",
    "    else:\n",
    "        df=df_lst[0]\n",
    "        des=des_lst[0]\n",
    "    with open('./'+path+'all_second'+'.csv','a') as f:\n",
    "        f.writelines('\\n' + ticker+str(int(fdate)) + '\\n')\n",
    "        f.writelines(url + '\\n')\n",
    "        des=re.sub('[\\n]',\"\",des)\n",
    "        des=re.sub(' +',\" \",des)\n",
    "        f.writelines('\"'+des+'\"'+'\\n')\n",
    "        try: df.to_csv(f,encoding='cp1252')\n",
    "        except: df.to_csv(f,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# used to generate a list of gvkeys for hedgers\n",
    "file_index=pd.read_csv('./data/sec_filing_final_wlinks.csv') # from Stata\n",
    "files=file_index.loc[~np.isnan(file_index.fdate)].reset_index()\n",
    "# files[~files.index.isin(index_lst)].to_csv('2016_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new version\n",
    "with open('log_second'+'.txt','w') as f: pass\n",
    "with open('./'+'volume/'+'all_second'+'.csv','w') as f: pass\n",
    "with open('./'+'hedge/'+'all_second'+'.csv','w') as f: pass\n",
    "bad_lst1=np.zeros(len(files))\n",
    "bad_lst2=np.zeros(len(files))\n",
    "for jj in range(1144,len(files)):\n",
    "    for path in ['volume/','hedge/']:\n",
    "        fname=files.fname[jj]\n",
    "        ticker=files.ticker[jj]\n",
    "        fdate=files.fdate[jj]\n",
    "        comnam=files.comnam[jj]\n",
    "        form=files.form[jj]\n",
    "        url=files.html[jj]\n",
    "        with open('log_second'+'.txt','a') as f:\n",
    "            f.writelines( str(jj)+ '\\n')\n",
    "    #     response = requests.get('https://www.sec.gov/Archives/'+fname)\n",
    "        try:\n",
    "            article_path='./data/sample/'+comnam+str(int(fdate))\n",
    "            with open(article_path, 'rb') as f:\n",
    "                article = f.read()\n",
    "                article = BeautifulSoup(article, 'html.parser')\n",
    "            output_table(article,ticker,fdate,form,path,url)\n",
    "        except: #complement w/ html\n",
    "            try:\n",
    "                article_path='./data/html_data/'+comnam+str(int(fdate))\n",
    "                with open(article_path, 'rb') as f:\n",
    "                    article = f.read()\n",
    "                    article = BeautifulSoup(article, 'html.parser')\n",
    "                output_table(article,ticker,fdate,form,path,url)\n",
    "            except:\n",
    "                with open('log_second'+'.txt','a') as f:\n",
    "                    f.writelines('\\n' + path+'bad' + '\\n')\n",
    "#                 print(path+'bad')\n",
    "                if path==\"volume/\": bad_lst1[jj]=1\n",
    "                if path==\"hedge/\": bad_lst2[jj]=1\n",
    "                sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################final code ends here###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the rest is for debugging"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
